---
title: "IEEE 754"
---

## Announcements

- **Welcome** to Systems in Rust
- **Action Items**:
  - "SHA-512" is due on next Friday
  - Lecture on numbers, inspired by the lab, while we wait.

## Today

- Understand the basics of floats
- Understand the language of floats
- Get a feel for when further investigation is required
- Have a few tools ready to help
- Be prepared to keep learning about IEEE floats

## Citation

- Yoinked
- [url](https://github.com/DigitalInBlue/CPPCon2015)
- Author John Farrier, Booz Allen Hamilton

## Mission Statement

- I'm a normal person.
    -   I think 5/2 is 2.5.
- I'm a scientist.
    - I'm solving "Black-Scholes"
    - [Does anyone know what this is doing?](https://numba.pydata.org/numba-examples/examples/finance/blackscholes/results.html)
$$
d_2 = d_1 - \sigma\sqrt{T - t} = \frac{1}{\sigma\sqrt{T - t}}\left[\ln\left(\frac{S_t}{K}\right) + \left(r - q - \frac{1}{2}\sigma^2\right)(T - t)\right]
$$

## Common Fallacies

- "Floating point numbers are numbers"
    - `max(count())` Pinocchios
- "Itâ€™s floating point error"
    - "All floating point involves magical rounding errors"
- "Linux and Windows handle floats differently"
- "Floating point represents an interval value near the actual value"

## Common Fallacies 2.0

- "A double (an `f64`) holds 15 decimal places and I only need 3, so I have nothing to worry about"[^1]
- "My programming language does better math than your programming language"[^2]
- "Why can't computers just store whatever number I use"[^3]

[^1]: Grammatically, this statement should be "so I have nothing about which to worry."
[^2]: This is true in the special case that your programming language is Rust.
[^3]: This is due to how many numbers there are.

## Anatomy of IEEE Floats

![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/IEEE754.svg/550px-IEEE754.svg.png)

## IEEE Float Specification

- IEEE 754-1985, IEEE 854-1987, IEEE 754-2008
    - These are paywalled.
    - Those are years.
- Provide for portable, provably consistent math
    - Consistent, not correct.

## Assurances

- Ensure some significant mathematical identities hold true:
    - $x + y  = y + x$
        - Symmetry of addition
    - $x + 0 = x$
        - Additive identity
    - $x = y \implies x - y = 0$
        - Identify under subtraction
        
## Assurances 2.0

    $$\frac{x}{\sqrt{x^2+y^2}} \leq 1$$

- What is missing?

## IEEE Float Specification

- Ensure every floating point number is unique
- Ensure every floating point number has an opposite
    - _Zero_ is a special case because of this
- Specifies algorithms for addition, subtraction, multiplication, division, and square-root
    - Not really operations/relations! They are algorithms.
    
    
## Aside: Scientific Notation

> [Scientific notation is a way of expressing numbers that are too large or too small to be conveniently written in decimal form, since to do so would require writing out an inconveniently long string of digits.](https://en.wikipedia.org/wiki/Scientific_notation)

- In scientific notation, nonzero numbers are written in the form 

$$a \times 10^b$$

## Aside: Explanation


- In scientific notation, nonzero numbers are written in the form 

$$a \times 10^b$$


* $a$ (the coefficient or mantissa) is a number greater than or equal to 1 and less than 10 ($1 \le |a| < 10$).
* $10$ is the base.
* $b$ (the exponent) is an integer.


## Aside: Physical Examples

1.  **Speed of light:** The speed of light in a vacuum is approximately $300,000,000 \text{ m/s}$
$$
3 \times 10^8 \text{ m/s}
$$

2.  **Mass of an electron:** The mass of an electron is approximately $0.00000000000000000000000000091093837 \text{ g}$.
$$
9.1093837 \times 10^{-28} \text{ g}
$$

## Aside: Economic Examples

- We can use social science numbers.
- [Labor Market Outcomes of College Graduates by Major](https://www.newyorkfed.org/research/college-labor-market#--:explore:outcomes-by-major)
- Computer Science majors in 2023 have a \$80,000 median wage "early career"
	- $8.0000 \times 10^4$
- And 6.1% unemployment
  	- $6.1 \times 10^{-2}$

## IEEE Layout

- An approximation using scientific notation
    - $x = -1^s \times 2^e \times 1.m$
    - $x = -1^{\text{sign bit}} \times \text{base} 2^{\text{exponent}} \times 1.\text{mantissa}$
        - Where the mantissa is the technical term for the the digits after the decimal point.
        
## With Binary{.smaller}

- $x = -0b1^{\text{0b0}} \times 0b10^{\text{0b10000000}}  \times 0b1.10010010000111111011011$
- Express in memory as the concatenation:
    - `0b0` to `0b10000000` to `0b10010010000111111011011`
    - `01000000010010010000111111011011`
        
## Singles and Doubles
        
- 32 - bits = 1 sign bit + 8 exponent bits + 23 mantissa bits
    - `0b0` to `0b10000000` to `0b10010010000111111011011`
- 64 - bits = 1 sign bit + 12 exponent bits + 52 mantissa bits

## Understanding check

- What is the probability a *real number* $a \in \mathbb{R}$ has an exact float representation?
- What is the probability an *integer* $n \in \mathbb{Z}$ has an exact float representation?
- What is the probability a *course number* $n < 600$ has an exact float representation?


# Special Floats - NaN

- Divide by Zero
    - 1 / 0
- Not a Number (NaN)

```py
>>> from numpy import float32 as f32
>>> f32(1)/f32(0)
<stdin>:1: RuntimeWarning: divide by zero encountered in scalar divide
np.float32(inf)
>>> 1/0
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ZeroDivisionError: division by zero
```

# Special Floats

- Signed Infinity
    - Overflow protection
- Signed Zero
    - Underflow protection, preserves sign
    - + 0 =âˆ’ 0


Now that we are experts...

https://github.com/DigitalInBlue/CPPCon


Simple Example

```
auto zeroPointOne = 0.1f;
auto zeroPointTwo = 0.2f;
auto zeroPointThree = 0.3f;
auto sum = zeroPointOne + zeroPointTwo;
```
```
cppCon() << "zeroPointOne == " << zeroPointOne << "\n";
cppCon() << "zeroPointTwo == " << zeroPointTwo << "\n";
cppCon() << "zeroPointThree == " << zeroPointThree << "\n";
cppCon() << "sum == " << sum << "\n";
```

## Simple Example


- zeroPointOne == 0.
- zeroPointTwo == 0.
- zeroPointThree == 0.
- sum == 0.
- zeroPointOne == 0. Simple Example
- zeroPointTwo == 0.
- zeroPointThree == 0.
- sum == 0.
- zeroPointOne == 0.
- zeroPointTwo == 0.
- zeroPointThree == 0.
- sum == 0.


Storage of 1.

1.

âˆ’ 1

```
ğ‘ ğ‘–ğ‘”ğ‘›ğµğ‘–ğ‘¡
Ã— ğ‘ğ‘ğ‘ ğ‘’
```
```
ğ‘’ğ‘¥ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡
Ã— 1. ğ‘šğ‘ğ‘›ğ‘¡ğ‘–ğ‘ ğ‘ ğ‘
```
âˆ’ 1

```
0
Ã— 2
```
```
0
Ã— 1. 0
```

Storage of 1.

1.

âˆ’ 1

```
ğ‘ ğ‘–ğ‘”ğ‘›ğµğ‘–ğ‘¡
Ã— ğ‘ğ‘ğ‘ ğ‘’
```
```
ğ‘’ğ‘¥ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡
Ã— 1. ğ‘šğ‘ğ‘›ğ‘¡ğ‘–ğ‘ ğ‘ ğ‘
```
âˆ’ 1

```
0
Ã— 2
```
```
0
Ã— 1. 0
```
[0][00000000][ 00000000000000000000000 ]


Storage of 1.

1.

âˆ’ 1

```
ğ‘ ğ‘–ğ‘”ğ‘›ğµğ‘–ğ‘¡
Ã— ğ‘ğ‘ğ‘ ğ‘’
```
```
ğ‘’ğ‘¥ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡
Ã— 1. ğ‘šğ‘ğ‘›ğ‘¡ğ‘–ğ‘ ğ‘ ğ‘
```
âˆ’ 1

```
0
Ã— 2
```
```
0
Ã— 1. 0
```
[0][01111111][00000000000000000000000]


Storage of 1.

- The exponent is _shift- 127_ encoded
- 0xeeeeeeee - 127

1.

âˆ’ 1

```
ğ‘ ğ‘–ğ‘”ğ‘›ğµğ‘–ğ‘¡
Ã— ğ‘ğ‘ğ‘ ğ‘’
```
```
ğ‘’ğ‘¥ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡
Ã— 1. ğ‘šğ‘ğ‘›ğ‘¡ğ‘–ğ‘ ğ‘ ğ‘
```
âˆ’ 1

```
0
Ã— 2
```
```
0
Ã— 1. 0
```
[0][01111111][00000000000000000000000]


Storage of 1.

1.

[0][01111111][00000000000000000000000]


Storage of 1.0

1.0000000000000000

[0][01111111][00000000000000000000000]

[0][01111111][00000000000000000000001]

1.0000001192092896


"Epsilon"

- The difference between 1.0 and the next available floating point number
- Useful for programmatic "almost equal" computations
- std::numeric_limits<T>::epsilon


Significant Digits

- Significant digits measure precision
    - Remember the "exponent" field
    - They are not a magnitude
- How close is close enough?
    - Define as significant digits, not absolute error

```
Sign ExponentMantissa TotalExponent bias Bits precision Significant Digits
Half(IEEE 754-2008) 1 5 10 16 15 11 3 - 4
Single 1 8 23 32 127 24 6 - 9
Double 1 11 52 64 1023 53 15 - 17
x86 extended precision 1 15 64 80 16383 64 18 - 21
Quad 1 15 112 128 16383 113 33 - 36
http://www.cs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF
```

Storage of the Very Small

- For 32-bit floats, the minimum base 10 exponent is -36.
- How is 1. 0 ğ‘’âˆ’^37 represented?

1.0e- 37

[0][00000000][11011001110001111101110]

0.09999999e- 37


"Denormalized Number"

- Numbers that have a zero exponent
- Required when the exponent is below the minimum exponent
- Helps prevent underflow

1.0e- 37

[0][00000000][11011001110001111101110]

0.09999999e- 37


Floating Point Precision

- Representation is not uniform between numbers
- Most precision lies between 0.0 and 0.1
- Precision falls away
- std::nextafter


Floating Point Precision

```
http://blogs.msdn.com/b/dwayneneed/archive/2010/05/07/fun-with-floating-point.aspx
```

Floating Point Precision

The number of floats from 0.0

- ...to 0.1 = 1,036,831,949
- ...to 0.2 = 8,388,608
- ... to 0.4 = 8,388,608
- ... to 0.8 = 8,388,608
- ... to 1.6 = 8,388,608
- ... to 3.2 = 8,388,608


Errors in Floating Point

https://github.com/DigitalInBlue/CPPCon2015


Storage of Ï€

Ï€ = 3.14159265

Ï€f= 3.14159274

Î” = 0.00000009


Measuring Error: "Ulps"

- Units in Last Place
    - "Harrison" and "Goldberg" definitions
    - (6-8 definitions floating around)
- "The gap between the two floating-point numbers

nearest to x, even if x is one of them." â€“W. Kahan

- https://www.cs.berkeley.edu/~wkahan/LOG10HAF.TXT
- IEEE 754 requires that that elementary arithmetic

operations are correctly rounded to within 0. 5 ulps

- Transcendental functions are generally rounded to

between 0. 5 and 1. 0 ulps

Ï€ = 3.14159265

Ï€f= 3.14159274

Î” = 0.00000009

9 ulps


Measuring Error: "Relative Error"

- The difference between the "real" number and the

approximated number, divided by the "real" number.

Ï€ = 3.14159265

Ï€f= 3.14159274

Î” = 0.00000009

9 ulps

2.864789e- 8 Î²

ğœ‹ âˆ’ (ğœ‹ğ‘“)

ğœ‹

```
= 2. 864789 ğ‘’
âˆ’ 8
```

Rounding Error

- Induced by approximating an infinite range of numbers into a finite number of bits
- Math is done exactly, then rounded*
    - Towards the nearest
    - Towards Zero
    - Towards positive infinity (round up)
    - Towards negative infinity (round down)

*Look up "exactly rounded" as well


Rounding Error

- What about rounding the half-way case? (i.e. 0.5)
    - Round Up vs. Round Even
- Correct Rounding:
    - Basic operations (add, subtract, multiply, divide, sqrt) should return the number nearest the
       mathematical result.
    - If there is a tie, round to the number with an even mantissa


"Guard Bit", "Round Bit", "Sticky Bit"

- Only used while doing calculations
    - Not stored in the float itself
    - The mantissa is shifted in calculations to align radix
- The guard bits and round bits are extra precision
- The sticky bit is an OR of anything that shifts through it

[0][00000000][00000000000000000000000][G][R][S...]


"Guard Bit", "Round Bit", "Sticky Bit"

**[G][R][S]**

**[0][-][-]** - Round Down (do nothing)

**[1][0][0]** - Round Up if the mantissa LSB is 1

**[1][0][1]** - Round Up

**[1][1][0]** - Round Up

**[1][1][1]** - Round Up

[0][00000000][00000000000000000000000][G][R][S...]


Significance Error

- Compute the Area of a Triangle
    - Heronâ€™s Formula:
       - ğ´ = ğ‘¥+ğ‘¦ 2 +ğ‘ ğ‘¥+ğ‘¦ 2 +ğ‘ âˆ’ğ‘¥ ğ‘¥+ğ‘¦ 2 +ğ‘ âˆ’ğ‘¦ ğ‘¥+ğ‘¦ 2 +ğ‘ âˆ’ğ‘§
    - Kahanâ€™sAlgorithm:
       - Sort x, y, z such that ğ‘¥â‰¥ğ‘¦ â‰¥ğ‘§
       - If ğ‘§< ğ‘¥âˆ’ğ‘¦, then no such triangle exists.
       - Else ğ´ = (ğ‘¥+ğ‘¦+ğ‘§) Ã— ğ‘§âˆ’(ğ‘¥âˆ’ğ‘¦ )Ã— 4 (ğ‘§+ğ‘¥âˆ’ğ‘¦ )Ã—(ğ‘¥+ğ‘¦âˆ’ğ‘§)


Significance Error

```
/// Area of a triangle
/// From http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html
/// From https://www.cs.berkeley.edu/~wkahan/Triangle.pdf
TEST(CPPCon2015, AreaOfATriangleFloat)
{
const auto a = 100000.0f;
const auto b = 99999.99979f;
const auto c = 0.00029f;
```
```
ASSERT_TRUE(a >= b);
ASSERT_TRUE(b >= c);
```
```
auto heronsFormula = HeronsFormula(a, b, c);
auto kahansFormula = KahansFormula(a, b, c);
EXPECT_NE(kahansFormula, heronsFormula);
cppCon() << "Kahan: " << kahansFormula;
cppCon() << "Heron: " << heronsFormula;
cppCon() << "delta: " << kahansFormula - heronsFormula << "\n";
}
```

Significance Error

Heron: 0.000000000000000000000000000000

Kahan: 14.500000000000000000000000000000

delta: 14.500000000000000000000000000000


Significance Error

Heron: 0.000000000000000000000000000000

Kahan: 14.500000000000000000000000000000

delta: 14.500000000000000000000000000000

Hint: The Answer is 10.0


Significance Error

Heron: 0.000000000000000000000000000000

Kahan: 14.500000000000000000000000000000

delta: 14.500000000000000000000000000000

Heron: 9.999999809638328700000000000000

Kahan: 10.000000077021038000000000000000

delta: 0.000000267382709751018410000000


Significance Error - Use Stable Algorithms

- Loss of Significance
    - Keep big numbers with big numbers, little numbers with little numbers.
- Parentheses can help
- Analysis of Algorithms is Critical
- The compiler wonâ€™t re-arrange your math if it cannot prove it would yield the same

result, even if the computation would be faster

- ğ‘¥ = ğ‘âˆ’ ğ‘+ğ‘ âˆ’ğ‘ should not be replaced with ğ‘¥= 0
- See the "Kahanâ€™sAlgorithm" example


Significance Error â€“ Simulation Time

- Time is used to compute distance, velocity, acceleration
    - High frequency phenomena
    - Sensors: Doppler shift, pulse compression, PRF
- These computed values feed into other computed values which may or may not

require a time component

- Thousands of computations per frame of simulation
    - Thousands of little compounding errors per frame
- Combine with poor or nonexistent testing


Significance Error â€“ Simulation Time

- Accumulate Time (works for arbitrary

time steps)

auto totalFrames = size_t(0);
auto frameLength = 0.01f;
auto simTime = 0.0f;

// Run 120 Frames
auto simTime120Frames = 1.20f;
for(; totalFrames < 120; totalFrames++)
{
simTime += frameLength;
}

```
auto totalFrames = size_t(0);
auto frameLength = 0.01f;
auto simTime = 0.0f;
```
```
// Run 120 Frames
auto simTime120Frames = 1.20f;
totalFrames = 120;
simTime = totalFrames * frameLength;
```
- Delta Time (works for fixed time steps)


Significance Error â€“ Simulation Time

Accumulate Time (works for arbitrary time steps)

- 1.199999999999999955591079014994 !=
    **1.199999213218688964843750000000**
    (0.000000786781310990747329014994)
- 12.000000000000000000000000000000 !=
    **12.000179290771484375000000000000** (-
    0.000179290771484375000000000000)
- 120.000000000000000000000000000000 !=
    **120.007225036621093750000000000000** (-
    0.007225036621093750000000000000)
- 600.000000000000000000000000000000 !=
    **600.274414062500000000000000000000** (-
    0.274414062500000000000000000000)
- 3600.000000000000000000000000000000 !=
    **3603.204101562500000000000000000000** (-
    3.204101562500000000000000000000)

Delta Time (works for fixed time steps)

- 1.200000047683715820312500000000 !=
    **1.199999928474426269531250000000**
    (0.000000119209289550781250000000)
- 12.000000000000000000000000000000 ==
    **12.000000000000000000000000000000**
    (0.000000000000000000000000000000)
- 120.000000000000000000000000000000 ==
    **120.000000000000000000000000000000**
    (0.000000000000000000000000000000)
- 600.000000000000000000000000000000 ==
    **600.000000000000000000000000000000**
    (0.000000000000000000000000000000)
- -3600.000000000000000000000000000000 ==
    **3600.000000000000000000000000000000**
    (0.000000000000000000000000000000)


Significance Error â€“ Simulation Time

- "Sub-Microsecond Precision"
    - 1.2345e-6 seconds per frame (810044.5 Hz)


Significance Error â€“ Simulation Time

- "Sub-Microsecond Precision"
    - 1.2345e-6 seconds per frame (810044.5 Hz)

### 0.012345000170171261000000000000 !=

### 0.0148140005767345430

### (-0.002469000406563282000000000000)

### 12.345000267028809000000000000000 !=

### 11.701118469238281000000000000000

### (0.643881797790527340000000000000)


Significance Error â€“ Donâ€™t use IEEE Floats?

- Use integers
    - Very fast
    - Trade more precision for less range
    - Only input/output may be impacted by floating point conversions
    - Financial applications represent dollars as only cents or tenthâ€™s of cents
- Use a math library
    - Slower
    - Define your own level of accuracy
    - MPFR (w/C++ Wrapper), TTMath, Boost, GMP C++
    - CRlibm(Correctly Rounded Mathematical Library)

(Store simTimeas uint64_tand get microsecond precision for 584555 years.)


Algebraic Assumption Error

- Mathematical Identities
    - Traditional identities (associative, commutative, distributive) do not hold
- Distributive Rule does not apply: ğ‘¥ Ã—ğ‘¦ âˆ’ğ‘¥ Ã— ğ‘§ â‰  ğ‘¥ (ğ‘¦ âˆ’ğ‘§)
- Associative Rule does not apply: ğ‘¥ + ğ‘¦ +ğ‘§ â‰  ğ‘¥ +ğ‘¦ +ğ‘§
- Cannot interchange division and multiplication:

### ğ‘¥

### 10. 0

â‰  ğ‘¥ Ã— 0. 1

Does a naÃ¯ve compiler make these assumptions too?

https://msdn.microsoft.com/library/aa289157.aspx


Algebraic Assumption Error

```
const auto oneRadian = 0.15915494309f;
const auto control = 0.000000000015915494309f;
```
```
const auto oneRadianMultiplied = oneRadian * 1.0e-10f;
const auto oneRadianDivided = oneRadian / 1.0e10f;
```

Algebraic Assumption Error

```
const auto oneRadian = 0.15915494309f;
const auto control = 0.000000000015915494309f;
```
```
const auto oneRadianMultiplied = oneRadian * 1.0e-10f;
const auto oneRadianDivided = oneRadian / 1.0e10f;
```
Control: 0.000000000015915494616658421000
x*1.0e-10f: 0.000000000015915494616658421000(0.000000000000000000000000000000)
x/1.0e10f: 0.00000000001591549 2881934945000 (0.000000000000000001734723475977)
Relative Error: 0.000000108995891423546710000000


Floating Point Exceptions

- Enable floating point exceptions to be alerted when things go awry.

```
ğ‘¥is the exact result of the operation
Î±= 192 for single precision, 1536 for double
ğ‘¥ğ‘šğ‘ğ‘¥= 1. 111 ... 111 Ã— 2 ğ‘’ğ‘šğ‘–ğ‘›.
See <cfenv> -Floating Point Environment
```
IEEE 754 Exception Result when traps disabled Argument to trap handler

overflow Â±âˆ or Â±ğ‘¥ğ‘šğ‘ğ‘¥ round(ğ‘¥ 2 âˆ’ğ›¼)

underflow 0, 2 ğ‘’ğ‘šğ‘–ğ‘›or denormalized round(ğ‘¥ 2 ğ›¼)

divide by zero Â±âˆ invalid operation

invalid NaN invalid operation

inexact round( _x_ ) round( _x_ )


But Wait! Thereâ€™s More!

- Binary to Decimal Conversion Error
- Summation Error
- Propagation Error
- Underflow, Overflow
- Type Narrowing/Widening Rules


Miscellaneous Notes

[http://preshing.com/images/float-point-perf.png](http://preshing.com/images/float-point-perf.png)
https://github.com/DigitalInBlue/CPPCon2015


Use Your Compilerâ€™s Output

- warning C4244: â€˜initializingâ€™ : conversion from â€˜doubleâ€™ to

â€˜floatâ€™, possible loss of data

- warning C4056: overflow in floating point constant arithmetic
- warning C4305: 'identifier' : truncation from 'type1' to

'type2'

- warning: conversion to 'float' from 'int' may alter its value
- warning: floating constant exceeds range of â€˜doubleâ€™


Fused Multiply-Add (FMA)

- a = a + (b * c); a += b * c;
- Multiplier-accumulator (MAC Unit)
- One rounding
- Compiler Options
    - GCC = -mfma
    - VC++ = #pragma fp_contract (off)
- Reference: FMA3, FMA4
    - [http://en.wikipedia.org/wiki/FMA_instruction_set](http://en.wikipedia.org/wiki/FMA_instruction_set)


Streaming SIMD Extensions (SSE)

- SSE can provide significant performance gains
    - Supports integer, floating point, logical, conversion, shift, and shuffle operations
- C, C++, Fortran do not natively support SSE, but compiler-specific support exists


Float Tricks

```
/// Fast reciprocal square root approximation for x > 0.25
/// Quakeâ€™s float Q_rsqrt(float number) is much more entertaining.
inline float FastInvSqrt(float x)
{
int tmp = ((0x3f800000 << 1) + 0x3f800000 - *(long*)&x) >> 1;
auto y = *(float*)&tmp;
return y * (1.47f â€“ 0.47f * x * y * y);
}
```

Testing

- Design for Numerical Stability
- Perform Meaningful Testing
- Document assumptions
- Track sources of approximation
- Quantify goodness
    - Well conditioned algorithms
- Backward error analysis
    - Are the outputs identical for slightly
       modified inputs?

```
TEST(CPPCon2015, pointOnePlusPointTwo)
{
auto zeroPointOne = 0.1f;
auto zeroPointTwo = 0.2f;
auto zeroPointThree = 0.3f;
auto sum = zeroPointOne + zeroPointTwo;
```
```
EXPECT_DOUBLE_EQ(0.3f, zeroPointThree);
EXPECT_EQ(0.3f, zeroPointThree);
EXPECT_EQ(0.3f, sum);
```
```
EXPECT_EQ(zeroPointThree, sum);
EXPECT_DOUBLE_EQ(zeroPointThree, sum);
}
```

[http://xkcd.com/217/](http://xkcd.com/217/)
[http://www.explainxkcd.com/wiki/index.php/217:_e_to_the_pi_Minus_pi](http://www.explainxkcd.com/wiki/index.php/217:_e_to_the_pi_Minus_pi)

```
https://github.com/DigitalInBlue/CPPCon2015
```

# Demystifying Floating Point

John Farrier, Booz Allen Hamilton

```
https://github.com/DigitalInBlue/CPPCon2015
```

